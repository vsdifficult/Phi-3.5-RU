from src.standart_model import StandartModelEntity 
import torch
import matplotlib.pyplot as plt
import numpy as np

class Phi35MoERUModel(StandartModelEntity):

    def __init__(self, model_name="alvis44/Phi-3-mini-128k-instruct-RU"):
        super().__init__(model_name)
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = self.model.to(self.device)

    def transform(self, text):
        """Override the transform method to handle device placement."""
        try:
            if not text:
                raise ValueError("Input text cannot be empty.")
            inputs = self.tokenizer(text, return_tensors="pt", padding=True, truncation=True)
            inputs = {key: val.to(self.device) for key, val in inputs.items()}  # Move inputs to the correct device
            with torch.no_grad():
                outputs = self.model(**inputs)
            return outputs.last_hidden_state.cpu().numpy()  # Move result back to CPU for numpy conversion
        except Exception as e:
            return str(e)

    def predict(self, text):
        """A convenience method to directly return the model's output for a given text."""
        try:
            hidden_state = self.transform(text)
            return hidden_state
        except Exception as e:
            return str(e)

    def save_model(self, path):
        """Override save_model to ensure device state is preserved."""
        try:
            # Save the model and tokenizer
            self.model.to("cpu")  # Ensure the model is saved on CPU for compatibility
            super().save_model(path)
            self.model.to(self.device)  # Restore the original device
        except Exception as e:
            return str(e)

    def load_model(self, path):
        """Override load_model to move the model to the correct device after loading."""
        try:
            super().load_model(path)
            self.model = self.model.to(self.device)  # Move the loaded model to the correct device
        except Exception as e:
            return str(e)

    def generate_presentation(self):
        """Generate a detailed presentation of the model."""
        presentation = {
            "model_name": self.model_name,
            "architecture": str(self.model.config),
            "parameters": sum(p.numel() for p in self.model.parameters()),
            "device": self.device,
            "example_output": self.predict("Пример текста для демонстрации")
        }
        return presentation

    def visualize_embeddings(self, text):
        """Visualize the embeddings generated by the model."""
        try:
            embeddings = self.transform(text)
            plt.figure(figsize=(10, 6))
            plt.imshow(embeddings[0], cmap='viridis', aspect='auto')
            plt.colorbar()
            plt.title("Визуализация эмбеддингов")
            plt.xlabel("Размерность эмбеддинга")
            plt.ylabel("Токены")
            plt.show()
        except Exception as e:
            return str(e)
